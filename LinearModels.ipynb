{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, MLDataUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"./data/data.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter to 2020 tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2020 = filter(row -> row.year == 2020, data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select only numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the numerical column names\n",
    "colnames = [\n",
    "    \"acousticness\",\n",
    "    \"danceability\",\n",
    "    \"duration_ms\",\n",
    "    \"energy\",\n",
    "    \"explicit\",\n",
    "    \"instrumentalness\",\n",
    "    \"key\",\n",
    "    \"liveness\",\n",
    "    \"loudness\",\n",
    "    \"mode\",\n",
    "    \"speechiness\",\n",
    "    \"tempo\",\n",
    "    \"valence\",\n",
    "]\n",
    "\n",
    "X = data2020[:, colnames];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are first treating this as a regular regression problem where for each track we predict the raw popularity score which has a range from 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data2020.popularity;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Some helpful utility functions for getting/printing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function MSE(y, pred)\n",
    "    return sum((y - pred).^2)/(size(y)[1])  \n",
    "end\n",
    "\n",
    "function MAE(y, pred)\n",
    "    return sum(abs.(y - pred))/(size(y)[1])  \n",
    "end\n",
    "\n",
    "function printErrors(train_MSE, test_MSE, train_MAE, test_MAE)\n",
    "    println(\"Train MSE\\t\", train_MSE)\n",
    "    println(\"Test MSE \\t\", test_MSE) \n",
    "    println(\"\")\n",
    "    println(\"Train MAE\\t\", train_MAE)\n",
    "    println(\"Test MAE \\t\", test_MAE) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the splitobs function in `MLDataUtils.jl` to create a 70/30 train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest = splitobs(X, at = 0.7);\n",
    "ytrain, ytest = splitobs(y, at = 0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13-element Array{Float64,1}:\n",
       "   3.556333031481273\n",
       "  42.49117317540465\n",
       "  -3.699870676862822e-5\n",
       "  28.18543701136224\n",
       "   7.6032284100208685\n",
       "  -5.648683925200404\n",
       "  -0.06642517715708617\n",
       "   9.834405531504977\n",
       "  -1.7265355844651613\n",
       "   1.8097164391290763\n",
       " -12.426338260359858\n",
       "   0.10235244707290483\n",
       " -12.074245043281554"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_train = convert(Matrix, Xtrain) \\ convert(Array, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predict on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = convert(Matrix, Xtrain)*w_train;\n",
    "test_pred = convert(Matrix, Xtest)*w_train;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Report Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE\t444.1237426559384\n",
      "Test MSE \t485.18355833891275\n",
      "\n",
      "Train MAE\t14.737165131715496\n",
      "Test MAE \t15.608320215215517\n"
     ]
    }
   ],
   "source": [
    "train_MSE = MSE(ytrain, train_pred)\n",
    "test_MSE = MSE(ytest, test_pred)\n",
    "\n",
    "train_MAE = MAE(ytrain, train_pred)\n",
    "test_MAE = MAE(ytest, test_pred);\n",
    "\n",
    "printErrors(train_MSE, test_MSE, train_MAE, test_MAE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
